{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source \n",
    "! python3 -m pip install torch transformers sentencepiece h5py\n",
    "\n",
    "!mkdir protT5 # root directory for storing checkpoints, results etc\n",
    "!mkdir protT5/protT5_checkpoint # directory holding the ProtT5 checkpoint\n",
    "!mkdir protT5/sec_struct_checkpoint # directory storing the supervised classifier's checkpoint\n",
    "!mkdir protT5/output # directory for storing your embeddings & predictions\n",
    "!wget -nc -P protT5/ https://rostlab.org/~deepppi/example_seqs.fasta\n",
    "!wget -nc -P protT5/sec_struct_checkpoint http://data.bioembeddings.com/public/embeddings/feature_models/t5/secstruct_checkpoint.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the following you can define your desired output. Current options:\n",
    "# per_residue embeddings\n",
    "# per_protein embeddings\n",
    "# secondary structure predictions\n",
    "\n",
    "# Replace this file with your own (multi-)FASTA\n",
    "# Headers are expected to start with \">\";\n",
    "seq_path = \"./protT5/example_seqs.fasta\"\n",
    "\n",
    "# whether to retrieve embeddings for each residue in a protein \n",
    "# --> Lx1024 matrix per protein with L being the protein's length\n",
    "# as a rule of thumb: 1k proteins require around 1GB RAM/disk\n",
    "per_residue = True \n",
    "per_residue_path = \"./protT5/output/per_residue_embeddings.h5\" # where to store the embeddings\n",
    "\n",
    "# whether to retrieve per-protein embeddings \n",
    "# --> only one 1024-d vector per protein, irrespective of its length\n",
    "per_protein = True\n",
    "per_protein_path = \"./protT5/output/per_protein_embeddings.h5\" # where to store the embeddings\n",
    "\n",
    "# whether to retrieve secondary structure predictions\n",
    "# This can be replaced by your method after being trained on ProtT5 embeddings\n",
    "sec_struct = True\n",
    "sec_struct_path = \"./protT5/output/ss3_preds.fasta\" # file for storing predictions\n",
    "\n",
    "# make sure that either per-residue or per-protein embeddings are stored\n",
    "assert per_protein is True or per_residue is True or sec_struct is True, print(\n",
    "    \"Minimally, you need to active per_residue, per_protein or sec_struct. (or any combination)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0\n"
     ]
    }
   ],
   "source": [
    "#@title Import dependencies and check whether GPU is available. { display-mode: \"form\" }\n",
    "from transformers import T5EncoderModel, T5Tokenizer\n",
    "import torch\n",
    "import h5py\n",
    "import time\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Network architecture for secondary structure prediction. { display-mode: \"form\" }\n",
    "# Convolutional neural network (two convolutional layers) to predict secondary structure\n",
    "class ConvNet( torch.nn.Module ):\n",
    "    def __init__( self ):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # This is only called \"elmo_feature_extractor\" for historic reason\n",
    "        # CNN weights are trained on ProtT5 embeddings\n",
    "        self.elmo_feature_extractor = torch.nn.Sequential(\n",
    "                        torch.nn.Conv2d( 1024, 32, kernel_size=(7,1), padding=(3,0) ), # 7x32\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Dropout( 0.25 ),\n",
    "                        )\n",
    "        n_final_in = 32\n",
    "        self.dssp3_classifier = torch.nn.Sequential(\n",
    "                        torch.nn.Conv2d( n_final_in, 3, kernel_size=(7,1), padding=(3,0)) # 7\n",
    "                        )\n",
    "        \n",
    "        self.dssp8_classifier = torch.nn.Sequential(\n",
    "                        torch.nn.Conv2d( n_final_in, 8, kernel_size=(7,1), padding=(3,0))\n",
    "                        )\n",
    "        self.diso_classifier = torch.nn.Sequential(\n",
    "                        torch.nn.Conv2d( n_final_in, 2, kernel_size=(7,1), padding=(3,0))\n",
    "                        )\n",
    "        \n",
    "\n",
    "    def forward( self, x):\n",
    "        # IN: X = (B x L x F); OUT: (B x F x L, 1)\n",
    "        x = x.permute(0,2,1).unsqueeze(dim=-1) \n",
    "        x         = self.elmo_feature_extractor(x) # OUT: (B x 32 x L x 1)\n",
    "        d3_Yhat   = self.dssp3_classifier( x ).squeeze(dim=-1).permute(0,2,1) # OUT: (B x L x 3)\n",
    "        d8_Yhat   = self.dssp8_classifier( x ).squeeze(dim=-1).permute(0,2,1) # OUT: (B x L x 8)\n",
    "        diso_Yhat = self.diso_classifier(  x ).squeeze(dim=-1).permute(0,2,1) # OUT: (B x L x 2)\n",
    "        return d3_Yhat, d8_Yhat, diso_Yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Load the checkpoint for secondary structure prediction. { display-mode: \"form\" }\n",
    "def load_sec_struct_model():\n",
    "  checkpoint_dir=\"./protT5/sec_struct_checkpoint/secstruct_checkpoint.pt\"\n",
    "  state = torch.load( checkpoint_dir )\n",
    "  model = ConvNet()\n",
    "  model.load_state_dict(state['state_dict'])\n",
    "  model = model.eval()\n",
    "  model = model.to(device)\n",
    "  print('Loaded sec. struct. model from epoch: {:.1f}'.format(state['epoch']))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Load encoder-part of ProtT5 in half-precision. { display-mode: \"form\" }\n",
    "# Load ProtT5 in half-precision (more specifically: the encoder-part of ProtT5-XL-U50) \n",
    "def get_T5_model():\n",
    "    model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_half_uniref50-enc\")\n",
    "    model = model.to(device) # move model to GPU\n",
    "    model = model.eval() # set model to evaluation model\n",
    "    tokenizer = T5Tokenizer.from_pretrained('Rostlab/prot_t5_xl_half_uniref50-enc', do_lower_case=False)\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Read in file in fasta format. { display-mode: \"form\" }\n",
    "def read_fasta( fasta_path, split_char=\"!\", id_field=0):\n",
    "    '''\n",
    "        Reads in fasta file containing multiple sequences.\n",
    "        Split_char and id_field allow to control identifier extraction from header.\n",
    "        E.g.: set split_char=\"|\" and id_field=1 for SwissProt/UniProt Headers.\n",
    "        Returns dictionary holding multiple sequences or only single \n",
    "        sequence, depending on input file.\n",
    "    '''\n",
    "    \n",
    "    seqs = dict()\n",
    "    with open( fasta_path, 'r' ) as fasta_f:\n",
    "        for line in fasta_f:\n",
    "            # get uniprot ID from header and create new entry\n",
    "            if line.startswith('>'):\n",
    "                uniprot_id = line.replace('>', '').strip().split(split_char)[id_field]\n",
    "                # replace tokens that are mis-interpreted when loading h5\n",
    "                uniprot_id = uniprot_id.replace(\"/\",\"_\").replace(\".\",\"_\")\n",
    "                seqs[ uniprot_id ] = ''\n",
    "            else:\n",
    "                # repl. all whie-space chars and join seqs spanning multiple lines, drop gaps and cast to upper-case\n",
    "                seq= ''.join( line.split() ).upper().replace(\"-\",\"\")\n",
    "                # repl. all non-standard AAs and map them to unknown/X\n",
    "                seq = seq.replace('U','X').replace('Z','X').replace('O','X')\n",
    "                seqs[ uniprot_id ] += seq \n",
    "    example_id=next(iter(seqs))\n",
    "    print(\"Read {} sequences.\".format(len(seqs)))\n",
    "    print(\"Example:\\n{}\\n{}\".format(example_id,seqs[example_id]))\n",
    "\n",
    "    return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Generate embeddings. { display-mode: \"form\" }\n",
    "# Generate embeddings via batch-processing\n",
    "# per_residue indicates that embeddings for each residue in a protein should be returned.\n",
    "# per_protein indicates that embeddings for a whole protein should be returned (average-pooling)\n",
    "# max_residues gives the upper limit of residues within one batch\n",
    "# max_seq_len gives the upper sequences length for applying batch-processing\n",
    "# max_batch gives the upper number of sequences per batch\n",
    "def get_embeddings( model, tokenizer, seqs, per_residue, per_protein, sec_struct, \n",
    "                   max_residues=4000, max_seq_len=1000, max_batch=100 ):\n",
    "\n",
    "    if sec_struct:\n",
    "      sec_struct_model = load_sec_struct_model()\n",
    "\n",
    "    results = {\"residue_embs\" : dict(), \n",
    "               \"protein_embs\" : dict(),\n",
    "               \"sec_structs\" : dict() \n",
    "               }\n",
    "\n",
    "    # sort sequences according to length (reduces unnecessary padding --> speeds up embedding)\n",
    "    seq_dict   = sorted( seqs.items(), key=lambda kv: len( seqs[kv[0]] ), reverse=True )\n",
    "    start = time.time()\n",
    "    batch = list()\n",
    "    for seq_idx, (pdb_id, seq) in enumerate(seq_dict,1):\n",
    "        seq = seq\n",
    "        seq_len = len(seq)\n",
    "        seq = ' '.join(list(seq))\n",
    "        batch.append((pdb_id,seq,seq_len))\n",
    "\n",
    "        # count residues in current batch and add the last sequence length to\n",
    "        # avoid that batches with (n_res_batch > max_residues) get processed \n",
    "        n_res_batch = sum([ s_len for  _, _, s_len in batch ]) + seq_len \n",
    "        if len(batch) >= max_batch or n_res_batch>=max_residues or seq_idx==len(seq_dict) or seq_len>max_seq_len:\n",
    "            pdb_ids, seqs, seq_lens = zip(*batch)\n",
    "            batch = list()\n",
    "\n",
    "            # add_special_tokens adds extra token at the end of each sequence\n",
    "            token_encoding = tokenizer.batch_encode_plus(seqs, add_special_tokens=True, padding=\"longest\")\n",
    "            input_ids      = torch.tensor(token_encoding['input_ids']).to(device)\n",
    "            attention_mask = torch.tensor(token_encoding['attention_mask']).to(device)\n",
    "            \n",
    "            try:\n",
    "                with torch.no_grad():\n",
    "                    # returns: ( batch-size x max_seq_len_in_minibatch x embedding_dim )\n",
    "                    embedding_repr = model(input_ids, attention_mask=attention_mask)\n",
    "            except RuntimeError:\n",
    "                print(\"RuntimeError during embedding for {} (L={})\".format(pdb_id, seq_len))\n",
    "                continue\n",
    "\n",
    "            if sec_struct: # in case you want to predict secondary structure from embeddings\n",
    "              d3_Yhat, d8_Yhat, diso_Yhat = sec_struct_model(embedding_repr.last_hidden_state)\n",
    "\n",
    "\n",
    "            for batch_idx, identifier in enumerate(pdb_ids): # for each protein in the current mini-batch\n",
    "                s_len = seq_lens[batch_idx]\n",
    "                # slice off padding --> batch-size x seq_len x embedding_dim  \n",
    "                emb = embedding_repr.last_hidden_state[batch_idx,:s_len]\n",
    "                if sec_struct: # get classification results\n",
    "                    results[\"sec_structs\"][identifier] = torch.max( d3_Yhat[batch_idx,:s_len], dim=1 )[1].detach().cpu().numpy().squeeze()\n",
    "                if per_residue: # store per-residue embeddings (Lx1024)\n",
    "                    results[\"residue_embs\"][ identifier ] = emb.detach().cpu().numpy().squeeze()\n",
    "                if per_protein: # apply average-pooling to derive per-protein embeddings (1024-d)\n",
    "                    protein_emb = emb.mean(dim=0)\n",
    "                    results[\"protein_embs\"][identifier] = protein_emb.detach().cpu().numpy().squeeze()\n",
    "\n",
    "\n",
    "    passed_time=time.time()-start\n",
    "    avg_time = passed_time/len(results[\"residue_embs\"]) if per_residue else passed_time/len(results[\"protein_embs\"])\n",
    "    print('\\n############# EMBEDDING STATS #############')\n",
    "    print('Total number of per-residue embeddings: {}'.format(len(results[\"residue_embs\"])))\n",
    "    print('Total number of per-protein embeddings: {}'.format(len(results[\"protein_embs\"])))\n",
    "    print(\"Time for generating embeddings: {:.1f}[m] ({:.3f}[s/protein])\".format(\n",
    "        passed_time/60, avg_time ))\n",
    "    print('\\n############# END #############')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Write embeddings to disk. { display-mode: \"form\" }\n",
    "def save_embeddings(emb_dict,out_path):\n",
    "    with h5py.File(str(out_path), \"w\") as hf:\n",
    "        for sequence_id, embedding in emb_dict.items():\n",
    "            # noinspection PyUnboundLocalVariable\n",
    "            hf.create_dataset(sequence_id, data=embedding)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Write predictions to disk. { display-mode: \"form\" }\n",
    "def write_prediction_fasta(predictions, out_path):\n",
    "  class_mapping = {0:\"H\",1:\"E\",2:\"L\"} \n",
    "  with open(out_path, 'w+') as out_f:\n",
    "      out_f.write( '\\n'.join( \n",
    "          [ \">{}\\n{}\".format( \n",
    "              seq_id, ''.join( [class_mapping[j] for j in yhat] )) \n",
    "          for seq_id, yhat in predictions.items()\n",
    "          ] \n",
    "            ) )\n",
    "  return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 10 sequences.\n",
      "Example:\n",
      "HCMV_UL54_MERLIN\n",
      "MFFNPYLSGGVTGGAVAGGRRQRSQPGSAQGSGKRPPQKQFLQIVPRGVMFDGQTGLIKHKTGRLPLMFYREIKHLLSHDMVWPCPWRETLVGRVVGPIRFHTYDQTDAVLFFDSPENVSPRYRQHLVPSGNVLRFFGATEHGYSICVNVFGQRSYFYCEYSDTDRLREVIASVGELVPEPRTPYAVSVTPATKTSIYGYGTRPVPDLQCVSISNWTMARKIGEYLLEQGFPVYEVRVDPLTRLVIDRRITTFGWCSVNRYDWRQQGRASTCDIEVDCDVSDLVAVPDDSSWPRYRCLSFDIECMSGEGGFPCAEKSDDIVIQISCVCYETGGNTAVDQGIPNGNDGRGCTSEGVIFGHSGLHLFTIGTCGQVGPDVDVYEFPSEYELLLGFMLFFQRYAPAFVTGYNINSFDLKYILTRLEYLYKVDSQRFCKLPTAQGGRFFLHSPAVGFKRQYAAAFPSASHNNPASTAATKVYIAGSVVIDMYPVCMAKTNSPNYKLNTMAELYLRQRKDDLSYKDIPRCFVANAEGRAQVGRYCLQDAVLVRDLFNTINFHYEAGAIARLAKIPLRRVIFDGQQIRIYTSLLDECACRDFILPNHYSKGTTVPETNSVAVSPNAAIISTAAVPGDAGSVAAMFQMSPPLQSAPSSQDGVSPGSGSNSSSSVGVFSVGSGSSGGVGVSNDNHGAGGTAAVSYQGATVFEPEVGYYNDPVAVFDFASLYPSIIMAHNLCYSTLLVPGGEYPVDPADVYSVTLENGVTHRFVRASVRVSVLSELLNKWVSQRRAVRECMRECQDPVRRMLLDKEQMALKVTCNAFYGFTGVVNGMMPCLPIAASITRIGRDMLERTARFIKDNFSEPCFLHNFFNQEDYVVGTREGDSEESSTLPEGLETSSGGLNERRVEARVIYGDTDSVFVRFRGLTPQALVARGPSLAHYVTACLFVEPVKLEFEKVFVSLMMICKKRYIGKVEGASGLSMKGVDLVRKTACEFVKGVTRDVLSLLFEDREVSEAAVRLSRLSLDEVKKYGVPRGFWRILRRLVQARDDLYLHRVRVEDLVLSSVLSKDISLYRQSNLPHIAVIKRLAARSEELPSVGDRVFYVLTAPGVRAAPQGSSDNGDSVTTGVVSRSDAIDGTDDDADGGGVEESNRRGGEPAKKRARKPPSAVCNYEVAEDPSYVREHGVPIHADKYFEQVLKAVTNVLSPVFPGGETARKDKFLHMVLPRRLHLEPAFLPYSVKAHECC\n",
      "Loaded sec. struct. model from epoch: 18.0\n",
      "\n",
      "############# EMBEDDING STATS #############\n",
      "Total number of per-residue embeddings: 10\n",
      "Total number of per-protein embeddings: 10\n",
      "Time for generating embeddings: 0.1[m] (0.465[s/protein])\n",
      "\n",
      "############# END #############\n"
     ]
    }
   ],
   "source": [
    "################ DO STUFF\n",
    "\n",
    "# Load the encoder part of ProtT5-XL-U50 in half-precision (recommended)\n",
    "model, tokenizer = get_T5_model()\n",
    "\n",
    "# Load example fasta.\n",
    "#seqs = read_fasta( seq_path )\n",
    "seqs = read_fasta( \"query/multi.fasta\" )\n",
    "\n",
    "# Compute embeddings and/or secondary structure predictions\n",
    "results = get_embeddings( model, tokenizer, seqs,\n",
    "                         per_residue, per_protein, sec_struct)\n",
    "\n",
    "# Store per-residue embeddings\n",
    "if per_residue:\n",
    "  save_embeddings(results[\"residue_embs\"], per_residue_path)\n",
    "if per_protein:\n",
    "  save_embeddings(results[\"protein_embs\"], per_protein_path)\n",
    "if sec_struct:\n",
    "  write_prediction_fasta(results[\"sec_structs\"], sec_struct_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1242, 1024)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#results[\"residue_embs\"]\n",
    "#type(results[\"residue_embs\"])\n",
    "key = list(results[\"residue_embs\"].keys())[0]\n",
    "results[\"residue_embs\"][key].shape\n",
    "\n",
    "\n",
    "# okay so If i provide a fasta with a single sequence\n",
    "# the output is a dict where the first key is what i want to extract\n",
    "# this is a numpy ndarray, with shape num_residues * 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.14583294, -0.13765724, -0.10299139, ...,  0.13605453,\n",
       "       -0.16264729, -0.03594943], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"residue_embs\"][key][0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dbe9d7b1238d39ac78e49ec943e15880bff8ed2c167e4279c58e16a66db947a4"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ocml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
